core: {
    loguru_verbosity: 3
    hidpi: false
    debug_with_profiler: true //makes the profiler print when it starts and stops time
}

train: {
    dataset_name: "easypbr" //easypbr, phenorobcp1
    // dataset_name: "phenorobcp1" //easypbr, phenorobcp1
    // dataset_name: "dtu" //easypbr, phenorobcp1
    // dataset_name: "bmvs" //easypbr, phenorobcp1
    // dataset_name: "multiface" //easypbr, phenorobcp1
    with_viewer: true 
    with_visdom: false 
    with_tensorboard: false
    with_wandb: false
    // lr: 3e-5e
    // lr: 1e-4
    // lr: 3e-5 //better for siren as it makes the eikonal loss smooth
    // lr: 3e-4
    // lr: 5e-4
    lr: 1e-3
    // lr: 3e-3
    // lr: 1e-2
    // weight_decay: 1e-4
    weight_decay: 0.0
    // weight_decay: 1e-6
    save_checkpoint: false
    checkpoint_path: "/media/rosu/Data/phd/c_ws/src/phenorob/instant_ngp_2/checkpoints"
    // checkpoint_path: "/home/user/rosu/c_ws/src/instant_ngp_2/checkpoints"
}

model: {
    positions_mode: "xyz"
    values_mode: "none"
    pointnet_channels_per_layer: [16,32,64]
    pointnet_start_nr_channels: 32
    nr_downsamples: 3
    nr_blocks_down_stage: [3,3,3]
    nr_blocks_bottleneck: 1
    nr_blocks_up_stage: [2,2,2]
    nr_levels_down_with_normal_resnet: 2
    nr_levels_up_with_normal_resnet: 2
    compression_factor: 1.0
    dropout_last_layer: 0.0

    //we run some experiments by setting the string here which if it's none then we run with the default full model:
    // none - default model with full features
    // slice_no_deform - doesn't use delta weights for the slicing, by setting them to zero
    // pointnet_no_elevate - doesn't elevate the distributed points into a higher dimensional space before doing the max but still substracts the local mean
    // pointnet_no_local_mean - doesn't perform the local mean substraction of the xyz positions and just uses them as is
    // pointnet_no_elevate_no_local_mean - doesnt elevate and doesnt do local mean
    // splat - just does a mean of all the features that fall into the lattice vertex without any elevatation or mean substraction
    // attention_pool - does an attention based pooling for pointnet instead of the maxpool
    // experiment: "none" 
}

lattice_gpu: {
    // hash_table_capacity: 65536 //2pow16
    // hash_table_capacity: 131072 //2pow17
    hash_table_capacity: 262144 //2pow18
    // hash_table_capacity: 524288 //2pow19
    // hash_table_capacity: 1048576 //2pow20
    nr_sigmas: 1

    sigma_0: "0.02 3"  //for motorbike IMPORTANT: if you change this, change it also int he lnn_eval.cfg
   
}



loader_vol_ref: {
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/augustus-ps"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/lucy-ps"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/sokrates-ps"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/figure-mvs"
    dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/sokrates-mvs"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/vase-mvs"
    autostart: false
    preload: true //preload the meshes in memory which is usually quite fast if they are small, or continously read them from memory

    nr_samples_to_skip: 0
    nr_samples_to_read: -1
    shuffle: true
    rgb_subsample_factor: 8
    depth_subsample_factor: 8
    load_rgb_with_valid_depth: true
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset

    scene_translation: [0.1, -0.1, 1.2]
    scene_scale_multiplier: 1.0
}

loader_nerf: {
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/chair"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/drums"
    dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/ficus"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/hotdog"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/lego"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/materials"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/mic"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/ship"
    subsample_factor: 8
    autostart: false
    shuffle: true
    mode: "train" //train, val, test
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    scene_scale_multiplier: 0.137
}

loader_easypbr: {
    dataset_path: "/media/rosu/Data/data/easy_pbr_renders"
    // dataset_path: "/home/rosu/work/data/easy_pbr_render"
    // dataset_path: "/workspace/instant-ngp-tests/"
    object_name:"head"
    // object_name:"vase"
    // object_name:"hair2D"
    // object_name:"monstera"
    // object_name:"plane"
    subsample_factor: 2
    autostart: false
    shuffle: true
    // limit_to_nr_imgs: -1 //set to -1 to load all the images
    // limit_to_nr_imgs: 1 //set to -1 to load all the images
    limit_to_nr_imgs: 14 //set to -1 to load all the images
    // img_selector: "random" //when limiting the nr of images, we can either cloose them randomly or select the X furthest frames from each other
    img_selector: "furthest" //when limiting the nr of images, we can either cloose them randomly or select the X furthest frames from each other
    mode: "train" //train, val, test
    load_mask: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // scene_scale_multiplier: 0.3
    // scene_scale_multiplier: 0.0003
    scene_scale_multiplier: {
        head: 0.9
        vase: 0.00015
        hair2D: 0.1
        monstera: 1.0
        plane: 1.0
    }
}


loader_phenorob_cp1: {
    // dataset_path: "/media/rosu/Data/data/phenorob/days_on_field"
    // dataset_path: "/media/rosu/Data/data/phenorob/data_from_home/fines_leaves_plant_2"
    // scan_date: "2021_06_10_just_9" // has kalibr processed and colmap
    // scan_date: "2021_06_02_just_15" //has colmap processed
    // scan_date: "2021_06_02_just_3" //has colmap processed
    // scan_date: "2021_06_10_just_16" //has colmap processed
    // scan_date: "phenorob_format" //on home comp

    //for presenting
    //bean
    // dataset_path: "/media/rosu/Data/data/phenorob/days_on_field/selected_for_presenting_processed/bean"
    // scene_normalization_file: "/media/rosu/Data/data/phenorob/days_on_field/selected_for_presenting_processed/bean/scene_normalization.cfg" //this overrrides the scene_scale and multiplier and reads the values from a file
    //maiz
    dataset_path: "/media/rosu/Data/data/phenorob/days_on_field/selected_for_presenting_processed/maiz"
    scene_normalization_file: "/media/rosu/Data/data/phenorob/days_on_field/selected_for_presenting_processed/maiz/scene_normalization.cfg" //this overrrides the scene_scale and multiplier and reads the values from a file
    //sugarbeet
    // dataset_path: "/media/rosu/Data/data/phenorob/days_on_field/selected_for_presenting_processed/sugarbeet"
    // scene_normalization_file: "/media/rosu/Data/data/phenorob/days_on_field/selected_for_presenting_processed/sugarbeet/scene_normalization.cfg" //this overrrides the scene_scale and multiplier and reads the values from a file

    // scan_date: "2022_05_25"
    //NOT implemented yet the following two things
    restrict_to_date: "2022_06_03" //read only one date, if it's empty we read all of them
    // restrict_to_date: "2022_07_06" //read only one date, if it's empty we read all of them
    restrict_to_scan_nr: "" //read only one scan_nr like 78 for example. if empty we read all of them

    rotation_alignment_degrees: -90
    frame_nr_for_alignment: 12 //aligns the rotation to one fo the frames. Can also be -1 to not do any alignment
    // dataset_type: "raw"  // raw, processed (the raw one is just the jpegs directly from the nikon. The processed are the undistorted ones)
    // dataset_type: "processed_kalibr"  // raw, processed_kalibr, processed_colmap (the raw one is just the jpegs directly from the nikon. The processed_kalibr are undistorted ones and poses in metric space, processed_colmap has cloud from colmap but no metric poses)
    dataset_type: "processed_colmap"  // raw, processed_kalibr, processed_colmap (the raw one is just the jpegs directly from the nikon. The processed_kalibr are undistorted ones and poses in metric space, processed_colmap has cloud from colmap but no metric poses)
    load_poses: true
    load_intrinsics: true
    load_dense_cloud: false
    load_sparse_cloud: false
    load_depth_map: false
    load_visible_points: false
    load_depth_map_from_visible_points: false //can only be turned on when load_visible_points is true and load_depth_map is false

    rgb_subsample_factor: 2
    photoneo_subsample_factor: 1
    autostart: false
    shuffle: false
    load_as_shell: true
    mode: "all" //all, train, val, test
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset

    // for 2021_06_02_just_15
    // scene_scale_multiplier: 0.5
    // scene_translation: [-0.3, 8.5, 0.0]
    //for 2021_06_02_just_3
    // scene_scale_multiplier: 0.6
    // scene_translation: [-0.8, 9.0, 1.8]
    //for 2021_06_10_just_16
    scene_scale_multiplier: 0.6
    scene_translation: [-0.9, 10.0, 0.7]
}

loader_dtu: {

    // dataset_path: "/media/rosu/Data/data/pixel_nerf_data/dtu_dataset/rs_dtu_4/DTU"
    dataset_path: "/media/rosu/Data/data/neus_data/data_DTU"
    // dataset_path: "/home/user/rosu/data/neus_data/data_DTU"
    mode: "all"
    load_mask: true
    // restrict_to_scan_idx: 37
    // restrict_to_scene_name: "dtu_scan24" //house  //works
    // restrict_to_scene_name: "dtu_scan37" //scissors //works
    // restrict_to_scene_name: "dtu_scan40" //bricks //works
    // restrict_to_scene_name: "dtu_scan55" //bunny    //works but the corners of the box are not supervized
    // restrict_to_scene_name: "dtu_scan63" //fruits      //works
    // restrict_to_scene_name: "dtu_scan65" //skull     //works
    // restrict_to_scene_name: "dtu_scan69" //snowman    //works but corners of the box are not supervized well
    // restrict_to_scene_name: "dtu_scan83" //smurf      /works
    // restrict_to_scene_name: "dtu_scan97" //cans         /works
    // restrict_to_scene_name: "dtu_scan105" //bear         /works
    // restrict_to_scene_name: "dtu_scan106" //birds          //works 
    // restrict_to_scene_name: "dtu_scan110" //goldenbunny   //works
    // restrict_to_scene_name: "dtu_scan114" //budha       /fails sometimes randomly but it's in bounds
    // restrict_to_scene_name: "dtu_scan118" //angel    //works
    // restrict_to_scene_name: "dtu_scan122" //owl      //works

    restrict_to_scene_name: "bmvs_bear"    //works
    // restrict_to_scene_name: "bmvs_clock"      //works
    // restrict_to_scene_name: "bmvs_dog"       //works
    // restrict_to_scene_name: "bmvs_durian"    //works
    // restrict_to_scene_name: "bmvs_jade"      //works
    // restrict_to_scene_name: "bmvs_man"       //works
    // restrict_to_scene_name: "bmvs_sculpture"  //works 
    // restrict_to_scene_name: "bmvs_stone"     //works
    autostart: false
    read_with_bg_thread: false


    subsample_factor: 1
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    load_as_shell: true
    preload_to_gpu_tensors: false //preloads all the rgb and maks(if enabled) into cuda tensors. 
    scene_scale_multiplier: 0.4
    rotate_scene_x_axis_degrees: 115

}

loader_multiface: {

    dataset_path: "/media/rosu/Data/data/multiface/multiface_data" 


    subjects:{
        subject_0:{ 
            subject_name: "m--20180105--0000--002539136--GHS"
            sequence: "E027_Scrunch_Face_Squeeze_Eyes"
            test_cameras: [400049, 400017, 400012, 400002]
            timestep: 0 

            scene_rotate_x_angle: 150
            scene_translation: [0.07, 1.6, 2.3]
            scene_scale_multiplier: 0.0023
        }
        subject_1:{ 
            subject_name: "m--20180226--0000--6674443--GHS"
            sequence: "E027_Scrunch_Face_Squeeze_Eyes"
            test_cameras: [400049, 400017, 400012, 400002]
            timestep: 0 

            scene_rotate_x_angle: 200
            scene_translation: [-0.07, -0.65, 2.2]
            scene_scale_multiplier: 0.0023
        }
        subject_2:{ //yaser
            subject_name: "m--20180227--0000--6795937--GHS"
            sequence: "E057_Cheeks_Puffed"
            test_cameras: [400049, 400017, 400012, 400002]
            timestep: 0 

            scene_rotate_x_angle: -180
            // scene_translation: [0.0, 0.07, 2.45]
            scene_translation: [0.0, 0.0, 2.4]
            scene_scale_multiplier: 0.0023
        }
        subject_3:{ 
            subject_name: "m--20180406--0000--8870559--GHS"
            sequence: "E005_Eyes_Wide_Open"
            test_cameras: [400049, 400017, 400012, 400002]
            timestep: 0 

            scene_rotate_x_angle: 190
            scene_translation: [0.0, -0.35, 2.4]
            scene_scale_multiplier: 0.0023
        }
        subject_4:{ 
            subject_name: "m--20180418--0000--2183941--GHS"
            sequence: "E008_Smile_Mouth_Closed"
            test_cameras: [400049, 400017, 400012, 400002]
            timestep: 0 

            scene_rotate_x_angle: 190
            scene_translation: [-0.07, -0.35, 2.4]
            scene_scale_multiplier: 0.0023
        }
        subject_5:{  //stephen
            subject_name: "m--20180426--0000--002643814--GHS"
            sequence: "E019_Frown"
            test_cameras: [400049, 400017, 400012, 400002]
            timestep: 0 

            scene_rotate_x_angle: 190
            scene_translation: [0.0, -0.35, 2.4]
            scene_scale_multiplier: 0.0023
        }
        subject_6:{ 
            subject_name: "m--20180510--0000--5372021--GHS"
            sequence: "E008_Smile_Mouth_Closed"
            test_cameras: [400049, 400017, 400012, 400002]
            timestep: 0 

            scene_rotate_x_angle: 190
            scene_translation: [0.0, -0.35, 2.4]
            scene_scale_multiplier: 0.0023
        }
        subject_7:{ 
            subject_name: "m--20180927--0000--7889059--GHS"
            sequence: "E012_Jaw_Open_Huge_Smile"
            test_cameras: [400049, 400017, 400012, 400002]
            timestep: 0 

            scene_rotate_x_angle: 190
            scene_translation: [0.0, -0.35, 2.3]
            scene_scale_multiplier: 0.0023
        }

    }


    subsample_factor: 1
    load_as_shell: false
    autostart: false
    shuffle: true
    mode: "all" //all, train, val, test
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset

    scene_translation: [0.0, 0.0, 2.4]
    scene_scale_multiplier: 0.0023
}




visualization: {
    show_gui: true

    subsample_factor: 1
    enable_culling: false
    tonemap: "Linear" //Linear, Reinhardt, Unreal, FilmicALU, ACES

    cam: {
        fov: 30 //can be a float value (fov: 30.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        near: "auto" //can be a float value (near: 0.01) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        far: "auto" //can be a float value (far: 10,0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        exposure: 1.0 //can be floar or "auto"
    }

    scene: {
        floor_visible: false
        floor_metric: true
    }

    ssao: {
        auto_settings: false
        enable_ssao: false
        ao_downsample: 1
        kernel_radius: "auto" //can be a float value (kernel_radius: 10,0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        ao_power: 4
        ao_blur_sigma_spacial: 2.0
        ao_blur_sigma_depth: 0.0001
    }

    edl: {
        auto_settings: false
        enable_edl_lighting: true
        edl_strength: 0.0
    }

    background:{
        show_background_img: false
        background_img_path: ""
    }

    ibl: {
        enable_ibl: false
        show_environment_map: false
        // environment_map_path: "/media/rosu/Data/data/sibl/Desert_Highway/Road_to_MonumentValley_Ref.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/Footprint_Court/Footprint_Court_2k.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/Circus_Backstage/Circus_Backstage_3k.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/canary_wharf_4k.hdr"
        environment_map_path: "sibl/Barcelona_Rooftops/Barce_Rooftop_C_3k.hdr"
        // environment_cubemap_resolution: 2048
        environment_cubemap_resolution: 512
        irradiance_cubemap_resolution: 32
        prefilter_cubemap_resolution: 128
        brdf_lut_resolution: 512
    }

    lights:{
        nr_spot_lights: 3
        spot_light_0: {
            power: "auto" //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 2048
        }
        spot_light_1: {
            power: "auto" //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 1024
        }
        spot_light_2: {
            power: "auto"  //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 1024
        }
    }

}
